{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "596104c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Import required libraries for IBM Watson Machine Learning and document processing\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2927d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up API keys and configuration from environment variables\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "ibm_cloud_url = os.getenv(\"IBM_CLOUD_URL\")\n",
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "model_id = os.getenv(\"MODEL_ID\")\n",
    "\n",
    "\n",
    "\n",
    "# Validate that necessary credentials are available\n",
    "if not all([api_key, ibm_cloud_url, project_id]):\n",
    "    raise ValueError(\"Ensure the env variables API_KEY, IBM_CLOUD_URL, and PROJECT_ID are populated correctly.\")\n",
    "\n",
    "# Prepare credentials and model parameters\n",
    "creds = {\n",
    "    \"url\": ibm_cloud_url,\n",
    "    \"apikey\": api_key \n",
    "}\n",
    "\n",
    "params = {\n",
    "    GenParams.DECODING_METHOD: \"greedy\",\n",
    "    GenParams.MIN_NEW_TOKENS: 30,\n",
    "    GenParams.MAX_NEW_TOKENS: 3500,\n",
    "    GenParams.TEMPERATURE: 0.0,\n",
    "    GenParams.REPETITION_PENALTY: 1.05,\n",
    "    GenParams.RANDOM_SEED: 8888,\n",
    "}\n",
    "\n",
    "model = Model(model_id=model_id, params=params, credentials=creds, project_id=project_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98011c86",
   "metadata": {},
   "source": [
    "## Milvus vectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59beaa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skasmani/opt/anaconda3/envs/genai_py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from pymilvus import (\n",
    "    connections,\n",
    "    utility,\n",
    "    FieldSchema, CollectionSchema, DataType,\n",
    "    Collection,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3874e94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_host = os.getenv(\"MILVUS_HOST\", None)\n",
    "milvus_port = os.getenv(\"MILVUS_PORT\", None)\n",
    "milvus_server_pem_path = os.getenv(\"MILVUS_SERVER_PEM_PATH\", None)\n",
    "milvus_server_name = os.getenv(\"MILVUS_SERVER_NAME\", None)\n",
    "milvus_user = os.getenv(\"MILVUS_USER\", None)\n",
    "milvus_password = os.getenv(\"MILVUS_PASSWORD\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff10de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "connections.connect(\"default\", host=milvus_host, port=milvus_port, secure=True, server_pem_path=milvus_server_pem_path, server_name=milvus_server_name,user=milvus_user,password=milvus_password)\n",
    "\n",
    "COLLECTION_NAME = 'docs_new'\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)\n",
    "\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    collection = Collection(COLLECTION_NAME)\n",
    "    collection.load()\n",
    "else:\n",
    "    fields = [\n",
    "        FieldSchema(name=\"p_key\", dtype=DataType.INT64, is_primary=True, auto_id=False),\n",
    "        FieldSchema(name=\"doc_title\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"title\", dtype=DataType.VARCHAR, max_length=128),\n",
    "        FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=25000),\n",
    "        FieldSchema(name=\"text_emb\", dtype=DataType.FLOAT_VECTOR, dim=384),\n",
    "        FieldSchema(name=\"metadatas\", dtype=DataType.JSON)\n",
    "    ]\n",
    "    \n",
    "    schema = CollectionSchema(fields, 'docs_compare', enable_dynamic_field=True)\n",
    "    \n",
    "    collection = Collection(COLLECTION_NAME, schema, consistency_level=\"Strong\")\n",
    "    \n",
    "    index_params = {\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"metric_type\": \"L2\",\n",
    "        \"params\": {\"nlist\": 1024}\n",
    "    }\n",
    "    collection.create_index(field_name = \"text_emb\", index_params = index_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4088a7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does collection exist in Milvus: True\n",
      "Number of entities in collection: 0\n"
     ]
    }
   ],
   "source": [
    "has = utility.has_collection(COLLECTION_NAME)\n",
    "print(f\"Does collection exist in Milvus: {has}\")\n",
    "print(f'Number of entities in collection: {collection.num_entities}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09d1cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_encoder(text):\n",
    "    \"\"\"\n",
    "    Transform a sentence into embedding\n",
    "    args:\n",
    "        sentence: str\n",
    "    return:\n",
    "        sentences_embedding\n",
    "    \"\"\"\n",
    "    model_name = 'all-MiniLM-L6-v2'\n",
    "    model = SentenceTransformer(model_name)\n",
    "    emb_text = model.encode(text).tolist()\n",
    "    return emb_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5d5fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(file_names):\n",
    "    data_rows = []\n",
    "    for fn in file_names:\n",
    "        file = open(f\"data/json/{fn}.json\")\n",
    "        data = json.load(file)\n",
    "\n",
    "        not_metadata = [\"title\", \"text\"]\n",
    "        # data_rows = []\n",
    "        for i, dic in enumerate(data):\n",
    "            heading = {}\n",
    "            heading[\"p_key\"] = i\n",
    "            heading[\"doc_title\"] = fn\n",
    "            heading[\"metadatas\"] = {}\n",
    "            for k in dic:\n",
    "                if k not in not_metadata:\n",
    "                    heading[\"metadatas\"][k] = dic[k]\n",
    "                else:\n",
    "                    heading[k] = dic[k]\n",
    "                    if k == \"text\":\n",
    "                        heading[\"text_emb\"] = text_encoder(dic[k])\n",
    "                \n",
    "            data_rows.append(heading)\n",
    "            \n",
    "    return data_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53e1392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities in collection: 41\n"
     ]
    }
   ],
   "source": [
    "files_names = [\"new-3301-title\", \"new-5831-split-by-title\"]\n",
    "data_rows = data_processing(files_names)\n",
    "\n",
    "collection.load()\n",
    "collection.insert(data_rows)\n",
    "collection.flush()\n",
    "\n",
    "print(f'Number of entities in collection: {collection.num_entities}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75b54aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entities in collection: 41\n"
     ]
    }
   ],
   "source": [
    "connections.connect(\"default\", host=milvus_host, port=milvus_port, secure=True, server_pem_path=milvus_server_pem_path, server_name=milvus_server_name,user=milvus_user,password=milvus_password)\n",
    "\n",
    "COLLECTION_NAME = 'docs_new'\n",
    "collection = Collection(COLLECTION_NAME)\n",
    "collection.load()\n",
    "print(f'Number of entities in collection: {collection.num_entities}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "297b2876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched IDs:  [2]\n",
      "Distance to the query vector:  [0.9174755811691284]\n",
      "Matched articles: \n",
      "doc_title:  new-3301-title \n",
      "title:  Termination \n",
      "text:  a. IBM may terminate Licensee's license to use a Program if Licensee fails to comply with the IPLA, TDs or acquisition agreements, such as the International Passport Advantage Agreement (IPAA). Licensee will promptly destroy all copies of the Program after license termination. Any terms that by their nature extend beyond the termination remain in effect until fulfilled and apply to successors and assignees. \n",
      "Metadatas {'page_num': 3}\n"
     ]
    }
   ],
   "source": [
    "# query = \"IBM warrants an IBM Program as specified in its license agreement, Services using reasonable care and skill, and an Appliance component for its specified operating environment.\"\n",
    "query = '''The Client Originating Company may terminate this Agreement without cause on one month's notice to\n",
    "the IBM Originating Company, and the IBM Originating Company may terminate this Agreement on three\n",
    "months' notice to the Client Originating Company. Once terminated, no further EPs may be acquired by\n",
    "any participating Client Site under the Agreement.\n",
    "If Client acquired or renewed IBM Software Subscription and Support, Selected Support, or Cloud\n",
    "Services, or if Client acquired or renewed a Program's license prior to the notice of termination, IBM may\n",
    "either continue to provide such services or allow Client to use the Program for the remainder of the\n",
    "current term(s), or give Client a prorated refund.\n",
    "The Client Originating Company will be considered to have terminated this Agreement if neither it nor any\n",
    "of its participating Enterprise companies have placed orders for EPs for 24 consecutive months nor have\n",
    "Software Subscription and Support or Selected Support in effect.\n",
    "Either of us may terminate this Agreement if the other does not comply with any of its terms, provided the\n",
    "one not complying is given written notice and reasonable time to comply.\n",
    "Client agrees to promptly discontinue use of and destroy all of Client's copies of a Program upon\n",
    "termination of a license grant.\n",
    "Any terms that by their nature extend beyond termination remain in effect until fulfilled, and apply to\n",
    "respective successors and assignees.'''\n",
    "\n",
    "\n",
    "\n",
    "# query = \"\"\"An EP is subject to this Agreement when IBM accepts Client's order by i) sending an invoice or a PoE \n",
    "# including the level of authorized use, ii) making the Program or Cloud Service available, iii) shipping the \n",
    "# Appliance, or iv) providing the support, service, or solution.\"\"\"\n",
    "\n",
    "result = collection.search(\n",
    "    data=[text_encoder(query)],\n",
    "    anns_field=\"text_emb\",\n",
    "    param = {\"metric_type\": \"L2\"},\n",
    "    limit=1,\n",
    "    output_fields=[\"doc_title\", \"title\", \"text\", \"metadatas\"],\n",
    "    expr=f\"doc_title == 'new-5831-split-by-title'\",\n",
    ")\n",
    "\n",
    "\n",
    "for hits in result:\n",
    "    print(\"Matched IDs: \", hits.ids)\n",
    "    print(\"Distance to the query vector: \", hits.distances)\n",
    "    print(\"Matched articles: \")\n",
    "    for hit in hits:\n",
    "        print(\n",
    "            \"doc_title: \", \n",
    "            hit.entity.get(\"doc_title\"), \n",
    "            \"\\ntitle: \", \n",
    "            hit.entity.get(\"title\"), \n",
    "            \"\\ntext: \", \n",
    "            hit.entity.get(\"text\"), \n",
    "            \"\\nMetadatas\", \n",
    "            hit.entity.get(\"metadatas\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a15d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.40083086490631104 0.40911149978637695  0.41468530893325806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c765e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_compare_prompt(new_text, old_text):\n",
    "    prompt = f\"\"\"[INST] You are a lawyer representing a global company and you are needed to read a document focusing on legal terms. \\\n",
    "Given the following paragraphs of a New and Old document, compare the two paragraphs. Do not provide false information.\n",
    "\n",
    "State the similaries and differences in point form in the following output format:\n",
    "Differences:\n",
    "Similarities:\n",
    "\n",
    "New Document:\n",
    "{new_text}\n",
    "\n",
    "Old Document:\n",
    "{old_text}\n",
    "\n",
    "Differences: [/INST]\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for old json and find in milvus the new similar portion\n",
    "# Pass to llm for comparison\n",
    "\n",
    "file = open(f\"json/old-5831-split-by-title.json\")\n",
    "data = json.load(file)\n",
    "filter_on = 'new-5831-split-by-title'\n",
    "\n",
    "data_dict = {\n",
    "    \"old_text\": [],\n",
    "    \"new_text\": [],\n",
    "    \"distance_score\": [],\n",
    "    \"title_from_new\": [],\n",
    "    \"title_from_old\": [],\n",
    "    \"llm_result\": []\n",
    "}\n",
    "\n",
    "for i, dic in enumerate(data):\n",
    "    old_text = dic[\"text\"]\n",
    "    old_title = dic[\"title\"]\n",
    "\n",
    "    result = collection.search(\n",
    "        data=[text_encoder(old_text)],\n",
    "        anns_field=\"text_emb\",\n",
    "        param = {\"metric_type\": \"L2\"},\n",
    "        limit=1,\n",
    "        output_fields=[\"doc_title\", \"title\", \"text\", \"metadatas\"],\n",
    "        expr=f\"doc_title == '{filter_on}'\",\n",
    "    )\n",
    "    # print(f\"Distance score: {result[0].distances}\")\n",
    "    # print(f\"Title/Heading: {result[0][0].entity.get(\"title\")}\")\n",
    "    new_text = result[0][0].entity.get(\"text\")\n",
    "    prompt = para_compare_prompt(new_text, old_text)\n",
    "    differences = model.generate_text(prompt=prompt)\n",
    "    # print(differences)\n",
    "\n",
    "    # storing the data\n",
    "    data_dict[\"old_text\"].append(old_text)\n",
    "    data_dict[\"new_text\"].append(new_text)\n",
    "    data_dict[\"distance_score\"].append(result[0].distances)\n",
    "    data_dict[\"title_from_new\"].append(result[0][0].entity.get(\"title\"))\n",
    "    data_dict[\"title_from_old\"].append(old_title)\n",
    "    data_dict[\"llm_result\"].append(differences)\n",
    "\n",
    "    print(f\"Data point {i} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb1f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for k in data_dict:\n",
    "    df[k] = data_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f5bf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"./results/3301_approach2_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ffe34f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - The \"New Document\" does not include the warranty provision for the Program that was included in the \"Old Document\" (point e).\n",
      "- In the \"New Document\", the definition of Enterprise now states that it includes the set of legal entities that own, are owned by, or are under common ownership with the Client Originating Company by more than 50% (previously it was more than 500%).\n",
      "\n",
      "Similarities:\n",
      "- Both documents define the Client and how they accept the IPAA.\n",
      "- Both define the role of IBM and the Client Originating Company in coordinating activities.\n",
      "- Both define the duration of the IPAA.\n",
      "- Both list the ways IBM accepts client orders.\n",
      "- Both define the responsibility of the Client Originating Company for compliance with the terms by all Client Sites.\n"
     ]
    }
   ],
   "source": [
    "# old_text = ''' The Client Originating Company (identified as the Originating Site in the IPAA Enrollment Form) and each of its participating Enterprise companies (identified as an Additional Site in the IPAA Enrollment Form) (together, the Client) accept this IPAA by submitting an IPAA Enrollment Form to IBM or Client's chosen IBM Business Partner.\n",
    "# b. The IBM Originating Company that accepts the Client Originating Company's orders and the Client Originating Company agree to coordinate the activities of their own Enterprise under this IPAA. The Client Originating Company is responsible for compliance with the terms by all Client Sites assigned a Passport Advantage Site Number (each, a Site) under this IPAA.\n",
    "# c. Enterprise means the set of legal entities that, by more than 500%, owns, are owned by, or are under common ownership with the Client Originating Company.\n",
    "# d. This IPAA is effective on the date IBM accepts the initial order under this IPAA and remains in effect until the Client Originating Company or the IBM Originating Company terminates it as described in this IPAA. IBM accepts Client's orders by: i) sending a TD that includes the level of authorized use; ii) making a Program or Cloud Service available; iii) shipping an Appliance; or iv) providing the Services.\n",
    "# e. IBM warrants that the Program, when used in its specified operating environment, will conform to its specifications.'''\n",
    "# old_title = \"Agreement Termination\"\n",
    "# filter_on = 'new-5831-split-by-title'\n",
    "\n",
    "# result = collection.search(\n",
    "#     data=[text_encoder(old_text)],\n",
    "#     anns_field=\"text_emb\",\n",
    "#     param = {\"metric_type\": \"L2\"},\n",
    "#     limit=1,\n",
    "#     output_fields=[\"doc_title\", \"title\", \"text\", \"metadatas\"],\n",
    "#     expr=f\"doc_title == '{filter_on}'\",\n",
    "# )\n",
    "# print(f\"Distance score: {result[0].distances}\")\n",
    "# # print(f\"Title/Heading: {result[0][0].entity.get(\"title\")}\")\n",
    "# new_text = result[0][0].entity.get(\"text\")\n",
    "# prompt = para_compare_prompt(new_text, old_text)\n",
    "# differences = model.generate_text(prompt=prompt)\n",
    "# print(differences)\n",
    "\n",
    "# # storing the data\n",
    "# # data_dict[\"old_text\"].append(old_text)\n",
    "# # data_dict[\"new_text\"].append(new_text)\n",
    "# # data_dict[\"distance_score\"].append(result[0].distances)\n",
    "# # data_dict[\"title_from_new\"].append(result[0][0].entity.get(\"title\"))\n",
    "# # data_dict[\"title_from_old\"].append(old_title)\n",
    "# # data_dict[\"llm_result\"].append(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9167317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Differences:\n",
    "\n",
    "# * The new document contains detailed provisions about the use of Enterprise Products (EPs) and Non-IBM EPs, while the old document focuses on the termination of the Agreement and post-termination obligations.\n",
    "# * The new document includes provisions regarding the responsibilities of the parties, confidentiality, business conduct guidelines, and use of business contact and account usage information. These topics are not addressed in the old document.\n",
    "# * The new document provides for specific notice periods for withdrawal of certain offerings and termination of the Agreement, while the old document only mentions the notice periods for termination without cause and for termination due to non-compliance.\n",
    "# * The new document includes provisions regarding the use of third-party services and the transfer of Content, including personally identifiable information, across country borders. These topics are not addressed in the old document.\n",
    "\n",
    "# Similarities:\n",
    "\n",
    "# * Both documents allow the Client to terminate the Agreement without cause on notice and provide for the termination of the Agreement due to non-compliance.\n",
    "# * Both documents provide for the continuation of certain services or use of the Program for the remainder of the current term(s) in case of termination of Software Subscription and Support or Selected Support.\n",
    "# * Both documents provide for the discontinuation of use of and destruction of Programs upon termination of a license grant.\n",
    "# * Both documents provide that any terms that by their nature extend beyond termination remain in effect until fulfilled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7d1e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder for converting comparison results to DataFrame and displaying them\n",
    "\n",
    "# Example:\n",
    "# import pandas as pd\n",
    "# results_data = {\n",
    "#     \"Old Text\": [old_text],\n",
    "#     \"New Text\": [new_text],\n",
    "#     \"Comparison Result\": [comparison_results]\n",
    "# }\n",
    "# df = pd.DataFrame(results_data)\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd25d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Placeholder for exporting results to Excel\n",
    "\n",
    "# Example:\n",
    "# df.to_excel(\"comparison_results.xlsx\")\n",
    "\n",
    "# Remember to replace the placeholder with your actual code to export the DataFrame.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
